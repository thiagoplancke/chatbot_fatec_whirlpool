# -*- coding: utf-8 -*-
"""chat4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13iRZaqQSz5l1jZwl5ToXq5DodHpLuxfh
"""

from google import genai

client = genai.Client(api_key="sua api key")

import spacy
from sentence_transformers import SentenceTransformer, util
from transformers import pipeline
!python -m spacy download pt_core_news_lg
nlp = spacy.load("pt_core_news_lg")
import gradio as gr
import re

model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

faq = {

    "oi" : "Oi! Sou seu assistente virtual. Em que posso ajudar?",


    "ola" : "Ol√°! Sou seu assistente virtual. Em que posso ajudar?",



    "preciso de ajuda" : "Ol√°! Sou seu assistente virtual. Em que posso ajudar?",



    "Quero falar com o suporte humano": "O numero para o nosso suporte √©: 19 xxxx-xxx",



    "Preciso falar com o seu suporte" : "O numero para o nosso suporte √©: 19 xxxx-xxx",



    "minha m√°quina de lavar n√£o est√° ligando": "Verifique se o cabo de energia est√° bem conectado e se h√° energia na tomada. Se o problema persistir, entre em contato com a assist√™ncia t√©cnica.",



    "a m√°quina de lavar est√° fazendo barulho": "Certifique-se de que n√£o h√° moedas, bot√µes ou objetos soltos no tambor. Barulhos fortes tamb√©m podem indicar desequil√≠brio na carga.",



    "como limpar o filtro da m√°quina de lavar": "Desligue a m√°quina da tomada, abra a tampa inferior e retire o filtro girando-o no sentido anti-hor√°rio. Lave com √°gua corrente e recoloque.",



    "a roupa sai muito molhada da m√°quina": "Verifique se o ciclo de centrifuga√ß√£o est√° selecionado corretamente. Cargas muito grandes ou mal distribu√≠das podem afetar o desempenho.",



    "como fa√ßo para usar o modo econ√¥mico da m√°quina": "Selecione o ciclo ‚ÄòEcon√¥mico‚Äô ou ‚ÄòR√°pido‚Äô no painel e use a quantidade de sab√£o indicada no manual. Isso economiza √°gua e energia.",



    "a m√°quina est√° com mau cheiro": "Recomenda-se fazer uma lavagem com o tambor vazio, utilizando vinagre branco ou produtos espec√≠ficos para limpeza de m√°quinas.",



    "meu fog√£o n√£o est√° acendendo": "Verifique se o g√°s est√° aberto e se o acendimento autom√°tico est√° funcionando. Caso use f√≥sforo, veja se o queimador n√£o est√° entupido.",


    "como limpar o forno do fog√£o": "Use um pano √∫mido com detergente neutro. Evite produtos abrasivos. Para sujeiras pesadas, use vinagre morno e bicarbonato.",



    "meu forno n√£o aquece direito": "Verifique se o seletor de temperatura est√° funcionando e se o acendimento est√° completo. Caso o problema continue, pode ser falha no termostato.",



    "como saber o tamanho do botij√£o ideal": "Verifique o manual do seu modelo. A maioria dos fog√µes dom√©sticos utiliza botij√µes de 13 kg com v√°lvula padr√£o.",



    "quanto tempo dura o acendimento autom√°tico": "Depende do modelo, mas em m√©dia o acendimento deve ocorrer em at√© 3 segundos ap√≥s pressionar o bot√£o."



}


def limpar_texto(texto):
    texto = texto.lower()

    texto_sem_pontuacao = re.sub(r'[^\w\s]', '', texto)

    texto_final = ' '.join(texto_sem_pontuacao.split())

    return texto_final

def preprocessar(texto):

    doc = nlp(texto.lower())

    tokens_validos = []



    for token in doc:

        if not token.is_stop and token.is_alpha:

            tokens_validos.append(token.lemma_)



    return " ".join(tokens_validos)


faq_list = list(faq.keys())

faq_processadas = []

for pergunta in faq_list:
    texto_processado = preprocessar(pergunta)
    pergunta_sem_pontuacao = limpar_texto(texto_processado)

    faq_processadas.append(pergunta_sem_pontuacao)

faq_embeddings = model.encode(faq_processadas, convert_to_tensor=True)


def responder_mensagem(mensagem, historico=None):








    sem_pontuacao = limpar_texto(mensagem)
    usuario_limpo = preprocessar(sem_pontuacao).lower()
    usuario_embedding = model.encode(usuario_limpo, convert_to_tensor=True)

    similaridades = util.cos_sim(usuario_embedding, faq_embeddings)[0]
    indice = similaridades.argmax().item()
    melhor_pergunta = faq_list[indice]
    melhor_resposta = faq[melhor_pergunta]
    pontuacao = similaridades[indice].item()

    # Escolher resposta
    if pontuacao <= 0.64:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=f"Voc√™ √© um chatbot para a whirlpool de Rio Claro e a pergunta do cliente n√£o se encontra dentro da FAQ, por√©m auxilie ele a fazer perguntas sobre a FAQ no caso: {faq_list}. empresa que no caso √© a whirlpool de rio claro que produz maquina de lavar e fogao e tamb√©m n√£o precisa dar todas op√ß√µes de faq ao usuario, caso a mensagem do usuario seja sauda√ß√µes, agradeciemntos ou despedidas apenas responda de forma breve e cordialmente a pergunta dele foi: {mensagem}"
        )
        resposta = f"{response.text}"
    else:
        resposta = melhor_resposta

    return resposta
import gradio as gr

gr.ChatInterface(
    fn=responder_mensagem,
    title="ChatBot Whirlpool üß†",
    description="Chat de exemplo com Gradio atualizado."
).launch(share=True)

